## 消息队列相关知识及面试点
---
> 参考资料 
> https://doocs.github.io/advanced-java/#/
> https://juejin.cn/post/6844903766743842823
> https://blog.csdn.net/u014437791/article/details/89454701

---

### 消息队列的常见使用场景
- 期待的回答: 哪个业务场景下，有什么技术挑战，不用MQ会比较麻烦，使用MQ之后带来很多好处
- 常见 的使用场景:
  - 解耦:
  - 异步:
  - 削峰:

---

### 常见消息队列的选型、对比

|特性 | ActiveMQ | RabbitMQ | RocketMQ | Kafka|
|:---|:--------|:------|:-------|:-----|
|单机吞吐量| 万级，比RocketMQ、Kafka低一个数量级 | 同ActiveMQ | 10万级，支持高吞吐量 | 10万级，高吞吐，配合大数据类的系统进行实时数据计算、日志采集等场景 |
|topic数量对吞吐量的影响| | | topic可以到百/千的级别，吞吐量会有较小服务的下降，RocketMQ的优势，同等机器下，可支撑大量的topic | topic从几十到击败的时候，吞吐量会大幅下降，同等机器侠，kafka尽量报证topic数量不要过多 |
|时效性| ms级 | 微秒级，延迟最低 | ms级 | ms级以内 |
|可用性| 高，基于主从架构，实现高可用 | 同Active MQ | 非常高，分布式架构 | 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 |
|消息可靠性| 有较低的概率丢失数据 | 基本不丢 | 经过参数优化配置，可以做到0丢失 | 同RocketMQ |
|功能支持| MQ领域的功能极其完备 | 基于erlang开发，并发能立很强，性能极好，延时很低 | MQ功能较为完善，分布式，扩展性好 | 功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算及日志采集被大规模使用 |

---

### 消息队列的高可用

>  高可用类的问题，需要针对不同的消息队列进行不同的回答，不同的消息队列采用不同的架构方案实现高可用，以下是 RabbitMQ 和 Kafka 的高可用架构简述
>

---

-  **RabbitMQ 的高可用**

 > RabbitMQ是基于主从(非分布式)架构做高可用的，有三种模式：单机、普通集群、镜像集群
 >

  - 单机模式：一般本地使用
  - 普通集群模式：(无高可用)
    - 在多台机器上启动多个RabbitMQ实例，每台集器启动一个。创建的queue，只会放在一个RabbitMQ实例上，但是每个实例都同步queue的元数据(queue的配置信息，通过元信息，找到queue所在实例)。当消费的时候，如果连接到了另外一个实例，则从queue所在的实例上拉取数据过来。![Image text](../../imgs/RabbitMQ普通集群.png)
    - 该方案主要目的在于提高吞吐量，让集群中多个节点来服务某个queue的读写操作。但该方案很麻烦，也没做到所谓的分布式。拉取数据的时候会导致要么随机连接一个实例再拉取数据(存在数据拉取的开销)，要么固定连接queue所在的实例的数据(单实例性能瓶颈)。
  - 镜像集群模式：(高可用)
    - 镜像集群模式下，创建的queue，无论元数据还是queue里的消息都会存在多个实例上，每个RabbitMQ节点都有这个queue的完整镜像，包含queue的全部数据，每次向queue中写数据的时候，会自动将消息同步到多个实例的queue上。![Image text](../../imgs/RabbitMQ镜像集群.png)
    
    - 通过RabbitMQ的管理控制台，可以新增相关的镜像集群模式策略，开启镜像集群模式。可以指定同步数据到所有节点还是只同步到指定数量的节点。

    - 该模式的好处是任何一个机器宕机了，都有其他的节点可以使用。坏处是:1.性能开销大(数据同步多分，网络带宽压力大)；2.扩展性低(机器上包含queue的所有数据，可能无法承载这些数据)
    
      
    
- **Kafka 的高可用 **
> kafka基本架构: 由多个broker组成，每个broker是一个节点；topic可划分为多个partition，每个partition可以存在于不同的broker上，每个paritition就放一部分数据。0.8之后，每个partition的数据会同步到其他机器上，形成自己的多个replica副本。提供HA机制。
> 

- 生产者发送的消息会被分为设置的partition个数量，发送到不同集器，同时每个partition的数据都会同步到其他机器上，形成自己的多个replica副本，所有replica会选举一个leader出来，那么生产和消费都跟这个leader打交道，然后其他replica就是follower。写的时候，leader会负责把数据同步到所有follower上去，读的时候就直接读leader上的数据即可。如果可以随意读写多个follower，那么就需要考虑数据一致性的问题了，复杂度太高。![Image text](../../imgs/kafka0.8高可用集群.png)
- 写数据时，生产者写leader，leader将数据落地写本地磁盘，接着其他follower自己主动从leader pull数据。一旦所有follower同步好数据，发送ack给leader,leader收到所有follower的ack之后，返回成功给生产者
- 消费时，只从leader去读，但只有一个消息已经被所有follower都同步成功返回ack的时候，消息才会被消费者看到 


---

### 消息队列的可靠性传输
> 可靠性传输主要指 如何确保消息不被丢失。要保证消息在传输的过程中，不多也不少。不多可以参考下述的重复消费问题，该处讨论如何处理消息不会丢失问题。
> 

- RabbitMQ处理方案
  > 消息丢失主要出现在以下三种情况 ![Image text](../../imgs/RabbitMQ消息丢失的三种情况.png)
  
  - 生产者丢失数据
  
    两种方案:
  
    - 开启RabbitMQ提供的事务功能，生产数据前开启事务 channel.txSelect，RabbitMQ接收异常回滚事务channel.txRollback，收到消息，提交事务channel.txCommit。事务是采用同步的方式，提交事务会将程序阻塞，影响吞吐量
    - 开启confirm模式。生产者开启confirm模式之后，每次写的消息都会分配一个唯一ID，如果写入到了RabbitMQ中，会回传一个ack消息，如果RabbitMQ没能处理，会回调一个nack接口，告诉你消息接受失败，可以重试。**confirm模式是异步的，推荐使用confirm模式**。
  
  - RabbitMQ丢失数据
  
    RabbitMQ自己弄丢数据，这个需要开启RabbitMQ持久化来保证，将消息持久化到磁盘，即时RabbitMQ挂了，恢复之后还可以自动读取之前的数据。配置持久化需要两个步骤:
  
    - 创建queue的时候，将其设置为持久化。该操作可以报证RabbitMQ持久化queue的元数据，但不会持久化queue里的数据。
    - 发送消息的时候将消息的deliveryMode设置为2。该配置是将消息设置为持久化。
    
    通过上述两个步骤，在加上生产数据的时候使用confirm模式，基本上可以报证在生产者和rabbitmq内部可以保证消息不会丢失。
  
  - 消费端丢失数据
  
    消费端处理丢失数据，可以关闭RabbitMQ的自动提交ack机制，改成手动提交，这样只有消息处理完成才提交ack，告诉RabbitMQ消息处理成功
  
    ![Image text](../../imgs/RabbitMQ消息丢失解决方案.png)


- Kakfa处理方案
  > kafka 的处理方案在结构上和rabbitmq类似，也是从三个部分出发，生产者端、kafka内部、消费者端

  - 消费者端丢失数据
  
    消费者端丢失数据，可以关闭自动提交offset，选择自己提交offset，只有对应消息处理成功之后，才发送offet。
    
  - kafka丢失数据
    
    > kafka丢失数据的场景一般为kafka某个broker宕机的时候，需要重新选leader，但正好把数据没有同步的follower选举为leader，导致数据丢失。

    针对该场景，要求kafka配置以下4个参数

      - topic设置 replication.factor，该值必须大于1，要求每个partition必须有至少2个副本
      - Kafka服务端设置 min.insync.replicas参数，该值必须大于1，要求一个leader至少感知到有至少一个follower还跟自己保持联系。
      - producer端设置acks=all，要求每条数据，必须写入所有replica之后，才能认为写入成功
      - producer端设置retries=MAX，一旦写入失败，就无限重试。

    以上四个参数至少可以报证在leader所在broker发生故障，进行leader切换时，数据不会丢失

  - 生产者端
    生产者端 设置 acks=all，一定不会丢。报证leader接收到消息后，所有follower都同步到消息之后之后才认为本次写入成功。

---

### 消息不被重复消费

- 不被重复消费的最终结论是报证消息的幂等性，所以就算是消息重复消费了只要保证消费的幂等性就可以(但能在生产者端先做到发送消息不重复最好)。幂等性，通俗来说，就是一个数据或者一个请求，重复来多少次，确保对应的结果数据不会改变。
- 报证幂等性的方案:
  - 数据库的唯一约束实现: 根据业务唯一编号，设置表中的唯一索引，根据唯一索引进行幂等性判断
  - 根据redis的原子性：根据redis的原子性特性，每次获取到消息都通过set方式存入redis。redis的数据是否落库也是问题。(考虑数据库和缓存数据的同步，可以使用databus类的中间件)
  - 唯一ID+指纹码机制(也是利用数据库的唯一性约束)；高并发时 可以根据ID进行分库分表的操作

---

### 消息的顺序性
> 消息的顺序性在有顺序要求的数据上极其重要。如同步数据库的数据时，原有的操作是增、改、删，但最终同步之后的顺序是 删、改、增，那这就出现了数据顺序不知道导致的数据问题。
> 

- 出现原因分析
  - RabbitMQ:rabbitmq出现顺序问题的主要原因，一个queue，多个consumer。多个consumer并不能报证哪个consumer先处理完成
  - Kafka:kafka在消息的生产和kafka内部，基本上不会出现顺序性的问题(生产的时候可以指定一个key，相同key会发送到同一个partition中，这两个过程都不会出现顺序性问题)。在消费端，如果使用单线程消费，效率很低，但如果使用多线程进行消息的消费，就可能会导致消息的顺序问题。
- 解决方法
  - RabbitMQ: 可以将整个queue拆分成多个queue，每个queue一个consumer；或者就一个queue对应一个consumer，但consumer内部使用内部队列操作，分发给底层的worker处理。
  - Kafka:可以用一个topic、一个partition、一个consumer，单线程消费，但效率太低；写多个queue，具有相同的key的数据，都到同一个内存queue中，consumer消费到之后，每个线程分别消费其中一个内存queue即可。

---

### 消息的延时及过期失效问题(包括消息堆积的问题)
> 该问题主要包括以下几个内容:消息队列满了？消息队列几百万的消息积压了几个小时？消息存在消息队列中，但由于设置了过期时间，消息过期失效了。。等等，针对这几个问题，基本上都是在具体场景具体分析，可根据相应场景进行分析。
>
 
- 大量消息积压在消息队列中几个小时
  大量消息积压，可能是消费端除了问题(消费端消费的慢、连接的mysql挂掉、连接的rpc挂掉、或者相关的程序问题)。针对这种情况，如果继续使用之前的消费者，消费的速度慢，可能需要耗时几个小时才消费完。如下给了一种解决方案:
    - 先修复consumer或者其他的相关问题，报证consumer能正常消费。然后停掉所有现有的consumer。
    - 新建一个topic，partition是原来的10倍，临时建立好10倍的queue数量。
    - 写一个临时的分发数据的consumer程序，该程序消费积压的数据，消费之后不做耗时的处理，直接均匀轮询的写入临时建立好的10倍数量的queue中
    - 临时征用10倍的机器部署consumer，用来消费临时queue中的数据。该做法相当于以正常10倍的速度来消费数据。
    - 消费完积压数据之后，恢复为原来的架构，重新使用原来的consumer机器来消费消息

- mq中的消息过期失效情况
  有些消息队列可以对数据设置TTL(过期时间)，如果消息积压了一定的时间，就会直接被RabbitMQ清理掉。针对这种情况一种可行的方式就是**批量重导**。对于已经丢失的数据肯定丢失了，可以等高峰期过去之后，重新写程序将丢失的数据找回来，重新灌入mq中。但如果针对那种实时性比较高的，就要尽量报证消息不丢失。

- mq快写满了
  针对这种情况，可以采用 先写程序，将消息消费到另一台磁盘充足的机器中，报证这台机器有空间容纳正常的业务，之后可以对该机器扩容或其他操作。等高峰期之后，再对数据进行重新push。

- 其他方案
  针对消息的消费，应该尽量避免再消息的处理过程中频繁的做一些IO量大的操作，尽量对消费过程进行优化。
  

---

### 如何设计一个消息队列
  该问题其实是一个发散性的问题，主要考察的是对架构的设计、消息队列的熟悉程度。
  归根结底可以从几个方面说：保障可用性、分布式、数据丢失、磁盘落地等。如果想进一步深入的设计的话，还涉及到多方面的，包括传输协议、文件落地的存储类型、


